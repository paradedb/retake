// Copyright (c) 2023-2025 Retake, Inc.
//
// This file is part of ParadeDB - Postgres for Search and Analytics
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see <http://www.gnu.org/licenses/>.

#![allow(dead_code)]
//! # ParadeDB Benchmarking
//!
//! This file contains two main parts:
//! 1. A `Benchmark` struct that uses [`sqlx`] and [`criterion`] to measure
//!    the execution time of one-off or iterative Postgres queries.
//! 2. A `BenchmarkSuite` (with a `run_all_benchmarks` function) that runs
//!    a series of benchmarks against Postgres using **pgbench** for load,
//!    collects top slow queries from `pg_stat_statements` (if available), logs them, and
//!    also showcases how to measure index creation time more idiomatically
//!    using Rust libraries instead of raw system calls for CPU/IO monitoring.
//!
//! `pgbench` is still invoked directly as it's the essential system
//! dependency for these benchmarks. Other Postgres admin tasks and
//! metrics collection are done via [`sqlx`] and other Rust crates.

use anyhow::{bail, Context, Result};
use async_std::task::block_on;
use chrono::Local;
use sqlx::postgres::PgConnectOptions;
use sqlx::{Connection, PgConnection};
use std::fs::{self, File, OpenOptions};
use std::io::{BufWriter, Write};
use std::path::{Path, PathBuf};
use std::process::{Command, Stdio};
use std::str::FromStr;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::time::{Duration, SystemTime};
use sysinfo::{Disks, System};

/// Configuration for the larger, pgbench-driven benchmark suite.
/// Adjust these fields as needed for your environment.
#[derive(Debug)]
pub struct BenchmarkSuiteConfig {
    /// Postgres connection string.
    pub db_url: String,
    /// Folder path containing `.sql` files (for pgbench's `--file` argument).
    pub sql_folder: PathBuf,
    /// Directory to store logs.
    pub log_dir: PathBuf,
    /// File path for an overall summary of the suite's results.
    pub summary_file: PathBuf,
    /// Directory for per-transaction logs generated by pgbench (`--log-prefix`).
    pub pgbench_log_subdir: PathBuf,
    /// Number of pgbench clients.
    pub clients: u32,
    /// Number of transactions per client in pgbench.
    pub transactions: u32,
    /// Additional flags for pgbench (e.g. `--log --report-per-command`).
    pub pgbench_extra_args: Vec<String>,
    /// Whether to run an index creation benchmark as well.
    pub skip_index: bool,
}

/// A higher-level benchmark suite that runs `pgbench` with custom SQL files
/// and collects additional stats from the DB. Also optionally benchmarks an
/// index creation step, measuring system resource usage in a more "Rusty" way
/// via the `sysinfo` crate (instead of raw `dstat` or `iostat` calls).
#[derive(Debug)]
pub struct BenchmarkSuite {
    pub config: BenchmarkSuiteConfig,
    /// We maintain a single connection pool or connection for convenience.
    /// If you're running many clients, you might want a real pool like `sqlx::Pool`.
    pub connection: Option<PgConnection>,
    /// Flag indicating if pg_stat_statements is available in this database.
    pub pg_stat_statements_available: bool,
}

impl BenchmarkSuite {
    /// Creates a new suite, ensuring logs directories exist, etc.
    pub async fn new(config: BenchmarkSuiteConfig) -> Result<Self> {
        // Create the primary log directory if needed.
        if !config.log_dir.exists() {
            fs::create_dir_all(&config.log_dir)
                .with_context(|| format!("Failed to create log directory: {:?}", config.log_dir))?;
        }
        // Create the pgbench log sub-directory if needed.
        if !config.pgbench_log_subdir.exists() {
            fs::create_dir_all(&config.pgbench_log_subdir).with_context(|| {
                format!(
                    "Failed to create pgbench log directory: {:?}",
                    config.pgbench_log_subdir
                )
            })?;
        }

        // If summary file doesn't exist, we'll create it:
        if !config.summary_file.exists() {
            File::create(&config.summary_file).with_context(|| {
                format!("Failed to create summary file: {:?}", config.summary_file)
            })?;
        }

        // Try connecting to the DB
        let conn_opts = PgConnectOptions::from_str(&config.db_url)
            .context("Invalid database URL for suite connection")?;
        let mut conn = PgConnection::connect_with(&conn_opts)
            .await
            .context("Failed to connect to Postgres in BenchmarkSuite::new")?;

        // Check if the pg_stat_statements extension is available in the system.
        // We check pg_available_extensions here.
        let stat_available: bool = sqlx::query_scalar(
            r#"
            SELECT EXISTS(
                SELECT 1 
                FROM pg_available_extensions 
                WHERE name = 'pg_stat_statements'
            );
            "#,
        )
        .fetch_one(&mut conn)
        .await
        .unwrap_or(false);

        let pg_stat_statements_available = if stat_available {
            // If available, try to create the extension (this is a no-op if it already exists)
            let _ = sqlx::query("CREATE EXTENSION IF NOT EXISTS pg_stat_statements;")
                .execute(&mut conn)
                .await;
            true
        } else {
            false
        };

        // Write an initial header to summary
        {
            let mut file = OpenOptions::new()
                .append(true)
                .write(true)
                .open(&config.summary_file)
                .with_context(|| {
                    format!("Failed to open summary file: {:?}", config.summary_file)
                })?;
            writeln!(
                file,
                "========================================================"
            )?;
            writeln!(file, " Benchmark Suite started at: {}", Local::now())?;
            writeln!(file, " DB URL: {}", config.db_url)?;
            writeln!(
                file,
                " Clients: {}, Transactions: {}",
                config.clients, config.transactions
            )?;
            writeln!(
                file,
                " pg_stat_statements available: {}",
                pg_stat_statements_available
            )?;
            writeln!(
                file,
                "========================================================\n"
            )?;
        }

        Ok(Self {
            config,
            connection: Some(conn),
            pg_stat_statements_available,
        })
    }

    /// Resets `pg_stat_statements` if available.
    async fn reset_pg_stat_statements(&mut self) -> Result<()> {
        if self.pg_stat_statements_available {
            if let Some(conn) = self.connection.as_mut() {
                sqlx::query("SELECT pg_stat_statements_reset()")
                    .execute(conn)
                    .await
                    .context("Failed to reset pg_stat_statements")?;
            }
        }
        // If not available, simply do nothing.
        Ok(())
    }

    /// Query the DB size (human-readable) and return it as a String.
    async fn fetch_db_size(&mut self) -> Result<String> {
        if let Some(conn) = self.connection.as_mut() {
            let size = sqlx::query_as::<_, (String,)>(
                r#"SELECT db_size FROM pg_size_pretty(pg_database_size(current_database())) AS db_size;"#,
            )
            .fetch_one(conn)
            .await
            .context("Failed to fetch database size")?
            .0 as String;

            Ok(size)
        } else {
            bail!("No connection available to fetch DB size.")
        }
    }

    /// Write a line to our summary file.
    fn write_summary_line(&self, line: &str) -> Result<()> {
        let mut file = OpenOptions::new()
            .append(true)
            .write(true)
            .open(&self.config.summary_file)
            .with_context(|| {
                format!(
                    "Failed to open summary file: {:?}",
                    self.config.summary_file
                )
            })?;
        writeln!(file, "{}", line)?;
        Ok(())
    }

    /// Check DB connection (just a quick test query).
    async fn check_db_connection(&mut self) -> Result<()> {
        if let Some(conn) = self.connection.as_mut() {
            let status = sqlx::query_as::<_, (String,)>("SELECT 'Connection OK' AS status")
                .fetch_one(conn)
                .await
                .context("Failed to check DB connection")?
                .0 as String;
            println!("DB Connection Test: {}", status);
        }
        Ok(())
    }

    /// Runs `pgbench` against the specified SQL file. Captures TPS, latency,
    /// logs them, and also queries the top 5 statements from `pg_stat_statements` if available.
    fn run_single_sql_pgbench(&mut self, sql_file: &Path, label: &str) -> Result<()> {
        let basefile = sql_file
            .file_stem()
            .and_then(|s| s.to_str())
            .unwrap_or("unknown");

        let out_prefix = self
            .config
            .log_dir
            .join(format!("{}_{}", label, basefile))
            .to_string_lossy()
            .to_string();
        let out_log = format!("{}_pgbench.log", out_prefix);

        println!("------------------------------------------------------");
        println!(" Running pgbench for: {}", sql_file.display());
        println!(" Label: {} / basefile: {}", label, basefile);
        println!(
            " Clients: {}, Transactions/Client: {}",
            self.config.clients, self.config.transactions
        );
        println!(" pgbench stdout/stderr will go to: {}", out_log);
        println!(
            " Per-transaction logs: {}/pgbench_log.<PID>",
            self.config.pgbench_log_subdir.display()
        );
        println!("------------------------------------------------------");

        // Construct pgbench command
        let mut cmd = Command::new("pgbench");
        cmd.arg("--client")
            .arg(self.config.clients.to_string())
            .arg("--transactions")
            .arg(self.config.transactions.to_string())
            .arg("--no-vacuum")
            .args(&self.config.pgbench_extra_args)
            .arg("--log-prefix")
            .arg(
                self.config
                    .pgbench_log_subdir
                    .join("pgbench_log")
                    .to_string_lossy()
                    .to_string(),
            )
            .arg("--file")
            .arg(sql_file)
            .arg(&self.config.db_url);

        // Run pgbench, capturing stdout/stderr
        let output = cmd
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .output()
            .with_context(|| format!("Failed to run pgbench for {}", sql_file.display()))?;

        // Write pgbench output to a file
        {
            let mut log_file =
                File::create(&out_log).context("Failed to create pgbench output log file")?;
            log_file.write_all(&output.stdout)?;
            log_file.write_all(b"\n--- STDERR ---\n")?;
            log_file.write_all(&output.stderr)?;
        }

        if !output.status.success() {
            bail!(
                "pgbench returned a non-zero exit code for {} (label: {})",
                sql_file.display(),
                label
            );
        }

        // Parse the output to find TPS and latency lines
        let stdout_str = String::from_utf8_lossy(&output.stdout);
        let mut tps_line = "(No TPS line found)";
        let mut latency_line = "(No latency line found)";

        for line in stdout_str.lines() {
            if line.starts_with("tps =") {
                tps_line = line;
            }
            if line.starts_with("latency average =") {
                latency_line = line;
            }
        }

        // Record to summary
        self.write_summary_line(&format!("[{}-{}] {}", label, basefile, tps_line))?;
        self.write_summary_line(&format!("[{}-{}] {}", label, basefile, latency_line))?;
        self.write_summary_line("")?;

        // Fetch the top 5 statements in a separate helper to avoid overlapping borrows.
        // If pg_stat_statements is not available, this will simply do nothing.
        let rows = self.fetch_top_statements_sync()?;

        if self.pg_stat_statements_available {
            self.write_summary_line(&format!(
                "===== pg_stat_statements (Top 5 by total_time) for {}-{} =====",
                label, basefile
            ))?;

            for (query, calls, total_time, rows_fetched) in rows {
                self.write_summary_line(&format!(
                    "query: {}\ncalls: {}, total_time: {}, rows: {}",
                    query, calls, total_time, rows_fetched
                ))?;
                self.write_summary_line("-----------------------")?;
            }
            self.write_summary_line("")?;
        }

        Ok(())
    }

    /// Helper that does the async DB call inside `block_on`, returning
    /// the rows so the parent function can safely write logs afterward.
    /// If pg_stat_statements is not available, this returns an empty vector.
    fn fetch_top_statements_sync(&mut self) -> Result<Vec<(String, i64, String, i64)>> {
        if !self.pg_stat_statements_available {
            return Ok(vec![]);
        }
        let conn = self.connection.as_mut().ok_or_else(|| {
            anyhow::anyhow!("No database connection available in fetch_top_statements_sync")
        })?;

        // Wrap the async call in block_on
        let rows = block_on(async {
            sqlx::query_as::<_, (String, i64, String, i64)>(
                r#"
            SELECT query,
                   calls,
                   to_char(total_plan_time + total_exec_time, 'FM999999999.00') AS total_time,
                   rows
            FROM pg_stat_statements
            ORDER BY (total_plan_time + total_exec_time) DESC
            LIMIT 5;
            "#,
            )
            .fetch_all(conn)
            .await
        })?;

        Ok(rows)
    }

    /// Demonstration of measuring system resource usage while building an index.
    ///
    /// - Drops the existing index if present.
    /// - Spawns a background thread collecting sysinfo stats every second.
    /// - Creates the index with [`sqlx`], measuring real time spent.
    /// - Stops the background thread and writes a CSV log of the stats.
    async fn benchmark_index_creation(&mut self) -> Result<()> {
        // Print to console for immediate feedback
        println!("==========================================================");
        println!("Starting Index Creation Benchmark (BM25)...");
        println!("==========================================================");

        self.write_summary_line("----- Benchmarking Index Creation -----")?;
        self.write_summary_line("Dropping existing index idx_benchmark_eslogs_bm25 (if any)...")?;

        println!("Dropping existing index idx_benchmark_eslogs_bm25 (if any)...");

        if let Some(conn) = self.connection.as_mut() {
            sqlx::query("DROP INDEX IF EXISTS idx_benchmark_eslogs_bm25;")
                .execute(conn)
                .await
                .context("Failed to drop index")?;
        }

        // Prepare for resource monitoring
        let dstat_csv = self.config.log_dir.join("index_creation_sysinfo.csv");
        self.write_summary_line(&format!(
            "Starting sysinfo-based resource monitor. Will log to: {:?}",
            dstat_csv
        ))?;

        println!(
            "Starting sysinfo-based resource monitor, logging to: {:?}",
            dstat_csv
        );

        // Write header and then drop the writer so the file is unlocked for appending
        {
            let mut csv_file = BufWriter::new(
                File::create(&dstat_csv)
                    .with_context(|| format!("Failed to create {:?}", dstat_csv))?,
            );
            writeln!(
                csv_file,
                "timestamp, cpu_usage_percent, total_memory, used_memory, disk_read, disk_write"
            )?;
            csv_file.flush()?;
        }

        let stop_flag = Arc::new(AtomicBool::new(false));
        let stop_flag_handle = stop_flag.clone();

        let handle = std::thread::spawn(move || {
            let mut sys = System::new_all();
            while !stop_flag_handle.load(Ordering::SeqCst) {
                sys.refresh_all();

                // For simplicity, let's just pick an average CPU usage across cores
                let avg_cpu_usage = sys
                    .cpus()
                    .iter()
                    .map(|cpu| cpu.cpu_usage() as f64)
                    .sum::<f64>()
                    / (sys.cpus().len() as f64);

                let total_mem = sys.total_memory();
                let used_mem = sys.used_memory();

                let disks = Disks::new();
                let total_read = disks.iter().map(|d| d.usage().read_bytes).sum::<u64>();
                let total_written = disks.iter().map(|d| d.usage().written_bytes).sum::<u64>();

                let now = Local::now().format("%Y-%m-%d %H:%M:%S");
                let line = format!(
                    "{}, {:.2}, {}, {}, {}, {}",
                    now, avg_cpu_usage, total_mem, used_mem, total_read, total_written
                );

                // Append each iteration
                if let Ok(mut f) = OpenOptions::new().append(true).open(&dstat_csv) {
                    let _ = writeln!(f, "{}", line);
                }

                std::thread::sleep(Duration::from_secs(1));
            }
        });

        // Actually create the BM25 index
        let create_index_sql = r#"
        CREATE INDEX idx_benchmark_eslogs_bm25
        ON public.benchmark_eslogs
        USING bm25 (
          id,
          process,
          cloud,
          aws_cloudwatch,
          agent,
          "timestamp",
          message,
          metrics_size,
          log_file_path
        )
        WITH (
          key_field = 'id',
          text_fields='{"message": {}, "log_file_path": {}}',
          numeric_fields='{"metrics_size": {}}',
          datetime_fields='{"timestamp": {}}',
          json_fields='{"process": {}, "cloud": {}, "aws_cloudwatch": {}, "agent": {}}'
        );
    "#;

        println!("Creating index idx_benchmark_eslogs_bm25...");
        self.write_summary_line("Creating index idx_benchmark_eslogs_bm25...")?;

        let start = SystemTime::now();

        if let Some(conn) = self.connection.as_mut() {
            sqlx::query(create_index_sql)
                .execute(conn)
                .await
                .context("Failed to create index with bm25")?;
        } else {
            bail!("No available connection for index creation");
        }

        let end = SystemTime::now();
        let duration = end.duration_since(start).unwrap_or_default();

        println!("Index creation took: {:.2?}", duration);
        self.write_summary_line(&format!("Index creation took: {:.2?}", duration))?;

        // Stop resource monitor
        stop_flag.store(true, Ordering::SeqCst);
        let _ = handle.join();

        println!("Index Creation Benchmark complete.");
        self.write_summary_line("----- Index Creation Benchmark Complete -----\n")?;

        Ok(())
    }

    /// Main entry point to run all benchmarks in the configured folder.
    ///
    /// - Resets `pg_stat_statements` (if available)
    /// - Prints DB size before
    /// - Launches pgbench for each `.sql` file
    /// - Prints DB size after
    /// - Optionally benchmarks index creation
    pub async fn run_all_benchmarks(&mut self) -> Result<()> {
        // 1) Quick DB check
        self.check_db_connection().await?;
        self.write_summary_line("DB connection OK.\n")?;

        // 2) DB size before
        let before_size = self.fetch_db_size().await?;
        self.write_summary_line(&format!("===== DB size BEFORE: {} =====", before_size))?;
        self.write_summary_line("")?;

        // 3) Reset pg_stat_statements if available
        self.reset_pg_stat_statements().await?;
        self.write_summary_line("pg_stat_statements reset (if available).")?;

        if !self.config.skip_index {
            self.benchmark_index_creation().await?;
        }

        // 4) For each .sql in folder, run pgbench
        self.write_summary_line(&format!(
            "\n********** BEGIN Benchmarking: {:?} **********",
            self.config.sql_folder
        ))?;

        let dir_entries = fs::read_dir(&self.config.sql_folder)
            .with_context(|| format!("Failed to read folder: {:?}", self.config.sql_folder))?;

        for entry in dir_entries {
            let path = entry?.path();
            if path.extension().and_then(|ext| ext.to_str()) == Some("sql") {
                // Reset pg_stat_statements for each run so the top 5 statements are relevant (if available)
                self.reset_pg_stat_statements().await?;
                self.run_single_sql_pgbench(&path, "pgsearch")?;
            }
        }

        // 6) Collect DB size after
        let after_size = self.fetch_db_size().await?;
        self.write_summary_line(&format!("===== DB size AFTER: {} =====", after_size))?;

        // 7) Final summary block
        self.write_summary_line("\n========================================================")?;
        self.write_summary_line(&format!("All tests completed at: {}", Local::now()))?;
        self.write_summary_line(&format!("Logs are in: {:?}", self.config.log_dir))?;
        self.write_summary_line(&format!(
            "Per-transaction logs are in: {:?}",
            self.config.pgbench_log_subdir
        ))?;
        self.write_summary_line(&format!(
            "Full summary file: {:?}",
            self.config.summary_file
        ))?;
        self.write_summary_line("========================================================\n")?;

        println!(
            "All benchmarks done. See summary at {:?}",
            self.config.summary_file
        );
        Ok(())
    }
}
